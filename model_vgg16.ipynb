{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "model_vgg16_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 92165     \n",
      "=================================================================\n",
      "Total params: 14,806,853\n",
      "Trainable params: 14,806,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(200,200, 3),name = 'image_input')\n",
    "\n",
    "output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(5, activation='softmax', name='predictions')(x)\n",
    "\n",
    "my_model = Model(inputs=input, outputs=x)\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3485 images belonging to 5 classes.\n",
      "Found 838 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generate datasets with keras library\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (200, 200),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (200, 200),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n"
     ]
    }
   ],
   "source": [
    "classes = training_set.class_indices\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - 62s 573ms/step - loss: 1.6259 - acc: 0.2989 - val_loss: 1.3469 - val_acc: 0.3846\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 62s 570ms/step - loss: 1.2396 - acc: 0.4703 - val_loss: 1.2365 - val_acc: 0.4938\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 58s 533ms/step - loss: 1.1784 - acc: 0.5182 - val_loss: 1.1133 - val_acc: 0.5261\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 58s 536ms/step - loss: 1.0969 - acc: 0.5551 - val_loss: 1.1999 - val_acc: 0.5310\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 1.0784 - acc: 0.5692 - val_loss: 1.0620 - val_acc: 0.5583\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 1.0594 - acc: 0.5817 - val_loss: 1.1312 - val_acc: 0.5087\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 59s 546ms/step - loss: 1.0245 - acc: 0.6006 - val_loss: 1.0430 - val_acc: 0.5682\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 1.0196 - acc: 0.6013 - val_loss: 1.0659 - val_acc: 0.5757\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 1.0112 - acc: 0.6090 - val_loss: 1.1121 - val_acc: 0.5397\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 59s 546ms/step - loss: 0.9659 - acc: 0.6271 - val_loss: 1.0065 - val_acc: 0.6191\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 57s 525ms/step - loss: 0.9527 - acc: 0.6380 - val_loss: 1.0174 - val_acc: 0.5918\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 55s 505ms/step - loss: 0.9257 - acc: 0.6489 - val_loss: 0.9655 - val_acc: 0.6576\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 55s 510ms/step - loss: 0.8590 - acc: 0.6707 - val_loss: 0.9119 - val_acc: 0.6228\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.8653 - acc: 0.6707 - val_loss: 0.9496 - val_acc: 0.6191\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.8188 - acc: 0.6912 - val_loss: 0.8651 - val_acc: 0.6489\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.7893 - acc: 0.6953 - val_loss: 0.9045 - val_acc: 0.6551\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.7663 - acc: 0.7119 - val_loss: 0.8582 - val_acc: 0.6476\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.7223 - acc: 0.7299 - val_loss: 0.8774 - val_acc: 0.6725\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.7058 - acc: 0.7287 - val_loss: 0.7611 - val_acc: 0.6985\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.6751 - acc: 0.7451 - val_loss: 0.7371 - val_acc: 0.7134\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.6433 - acc: 0.7576 - val_loss: 0.8475 - val_acc: 0.6799\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.6485 - acc: 0.7524 - val_loss: 0.6925 - val_acc: 0.7370\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.6527 - acc: 0.7570 - val_loss: 0.8113 - val_acc: 0.6861\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - 55s 513ms/step - loss: 0.5901 - acc: 0.7806 - val_loss: 0.7732 - val_acc: 0.7010\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5965 - acc: 0.7814 - val_loss: 0.8354 - val_acc: 0.7060\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - 55s 508ms/step - loss: 0.5935 - acc: 0.7819 - val_loss: 0.7184 - val_acc: 0.7320\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5709 - acc: 0.7915 - val_loss: 0.7435 - val_acc: 0.7184\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - 55s 508ms/step - loss: 0.5470 - acc: 0.7897 - val_loss: 0.6876 - val_acc: 0.7380\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5692 - acc: 0.7839 - val_loss: 0.7055 - val_acc: 0.7345\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5630 - acc: 0.7963 - val_loss: 0.6840 - val_acc: 0.7196\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5296 - acc: 0.7989 - val_loss: 0.7234 - val_acc: 0.7246\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5476 - acc: 0.7974 - val_loss: 0.6742 - val_acc: 0.7457\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5087 - acc: 0.8118 - val_loss: 0.7603 - val_acc: 0.7047\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.5287 - acc: 0.8126 - val_loss: 0.8278 - val_acc: 0.6675\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4976 - acc: 0.8167 - val_loss: 0.6748 - val_acc: 0.7543\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4542 - acc: 0.8336 - val_loss: 0.7183 - val_acc: 0.7556\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4716 - acc: 0.8187 - val_loss: 0.7435 - val_acc: 0.7270\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4537 - acc: 0.8309 - val_loss: 0.6742 - val_acc: 0.7444\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4199 - acc: 0.8433 - val_loss: 0.6604 - val_acc: 0.7543\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4360 - acc: 0.8428 - val_loss: 0.8210 - val_acc: 0.7357\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4266 - acc: 0.8384 - val_loss: 0.7494 - val_acc: 0.7419\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - 55s 506ms/step - loss: 0.4374 - acc: 0.8381 - val_loss: 0.7957 - val_acc: 0.7333\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4769 - acc: 0.8234 - val_loss: 0.7304 - val_acc: 0.7519\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4094 - acc: 0.8521 - val_loss: 0.8164 - val_acc: 0.7084\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4073 - acc: 0.8506 - val_loss: 0.7116 - val_acc: 0.7370\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4332 - acc: 0.8404 - val_loss: 0.6709 - val_acc: 0.7692\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.4005 - acc: 0.8479 - val_loss: 0.8303 - val_acc: 0.7246\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - 55s 506ms/step - loss: 0.3838 - acc: 0.8642 - val_loss: 0.7136 - val_acc: 0.7581\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - 55s 506ms/step - loss: 0.3976 - acc: 0.8592 - val_loss: 0.6779 - val_acc: 0.7581\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - 55s 507ms/step - loss: 0.3734 - acc: 0.8584 - val_loss: 0.8279 - val_acc: 0.7519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f254810e898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "my_model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 108,\n",
    "                         epochs = 50,\n",
    "                         validation_steps = 26,\n",
    "                         validation_data = test_set,\n",
    "                         callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "my_model_json = my_model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(my_model_json)\n",
    "# serialize weights to HDF5\n",
    "my_model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
